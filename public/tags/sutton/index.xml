<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Sutton on Harold</title>
    <link>http://localhost:1313/tags/sutton/</link>
    <description>Recent content in Sutton on Harold</description>
    <generator>Hugo</generator>
    <language>en</language>
    <lastBuildDate>Wed, 09 Apr 2025 14:59:13 +0800</lastBuildDate>
    <atom:link href="http://localhost:1313/tags/sutton/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>如果神经元也能上链：” Sutton 的下一代 AI 架构，会是 Web3 的终极叙事吗？</title>
      <link>http://localhost:1313/posts/sutton%E8%AE%BA%E6%96%87%E7%9A%84%E4%B8%80%E4%BA%9B%E8%B0%83%E7%A0%94/</link>
      <pubDate>Wed, 09 Apr 2025 14:59:13 +0800</pubDate>
      <guid>http://localhost:1313/posts/sutton%E8%AE%BA%E6%96%87%E7%9A%84%E4%B8%80%E4%BA%9B%E8%B0%83%E7%A0%94/</guid>
      <description>&lt;p&gt;近两天大致研究了 Rich Sutton 在强化学习领域的哲学思考和近期的研究成果，发现了Sutton教授在2024年&lt;a href=&#34;https://adai.ai/dai/2024/index.html&#34;  class=&#34;external-link&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;DAI 2024&lt;/a&gt;上的演讲, 从演讲题目来看，颇有Web3的风格: Decentralized Neural Networks&lt;sup id=&#34;fnref:1&#34;&gt;&lt;a href=&#34;#fn:1&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;1&lt;/a&gt;&lt;/sup&gt;.&lt;/p&gt;&#xA;&lt;p&gt;这篇介绍分两个部分，第一部分转述一下Sutton在这个Keynote中想要表达的思想，第二部分尝试将这个方向和区块链进行一些结合：&lt;/p&gt;&#xA;&lt;h2 id=&#34;sutton-眼中的decentralized-neural-networks&#34;&gt;&#xA;  Sutton 眼中的&amp;quot;Decentralized Neural Networks&amp;quot;&#xA;  &lt;a class=&#34;heading-link&#34; href=&#34;#sutton-%e7%9c%bc%e4%b8%ad%e7%9a%84decentralized-neural-networks&#34;&gt;&#xA;    &lt;i class=&#34;fa-solid fa-link&#34; aria-hidden=&#34;true&#34; title=&#34;Link to heading&#34;&gt;&lt;/i&gt;&#xA;    &lt;span class=&#34;sr-only&#34;&gt;Link to heading&lt;/span&gt;&#xA;  &lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;h3 id=&#34;总体思想从大脑比喻走向神经元自治&#34;&gt;&#xA;  总体思想：从“大脑比喻”走向“神经元自治”&#xA;  &lt;a class=&#34;heading-link&#34; href=&#34;#%e6%80%bb%e4%bd%93%e6%80%9d%e6%83%b3%e4%bb%8e%e5%a4%a7%e8%84%91%e6%af%94%e5%96%bb%e8%b5%b0%e5%90%91%e7%a5%9e%e7%bb%8f%e5%85%83%e8%87%aa%e6%b2%bb&#34;&gt;&#xA;    &lt;i class=&#34;fa-solid fa-link&#34; aria-hidden=&#34;true&#34; title=&#34;Link to heading&#34;&gt;&lt;/i&gt;&#xA;    &lt;span class=&#34;sr-only&#34;&gt;Link to heading&lt;/span&gt;&#xA;  &lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;p&gt;&lt;strong&gt;1. 对当前大模型的系统性批评&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;p&gt;Sutton 开篇就明确提出：当前的深度学习和人工神经网络存在致命问题，包括：&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;灾难性遗忘（Catastrophic forgetting）&lt;/li&gt;&#xA;&lt;li&gt;丧失可塑性（Plasticity collapse）&lt;/li&gt;&#xA;&lt;li&gt;在持续任务中性能退化（e.g. continual RL）&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;这与他一贯的观点一致：现代深度学习过于集中式、静态化、不适应现实世界的变化，而这正是他呼吁“持续学习”“互动学习”的背景。&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;2. 核心主张：神经元也是代理体，每个都有目标&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;p&gt;他在演讲中首次系统性提出了“去中心化神经网络（Decentralized Neural Networks, DNNs）”的定义：&lt;/p&gt;&#xA;&lt;p&gt;神经元不仅仅是被动计算单元，而是具有目标的主动体，它们的目标可以是：&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;使其他神经元“愿意听我说话”&lt;/li&gt;&#xA;&lt;li&gt;至少有 10% 的时间是活跃的&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;这从根本上挑战了目前神经网络中“被动单元+集中优化目标”的主流范式，将微观自治引入神经网络的每一个组成部分。&lt;/p&gt;&#xA;&lt;p&gt;这也延续了 Sutton 之前关于“智能是由一组目标驱动的学习系统组成的”观点（参考他和 Silver 等人的《Reward is Enough》&lt;sup id=&#34;fnref:2&#34;&gt;&lt;a href=&#34;#fn:2&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;2&lt;/a&gt;&lt;/sup&gt;论文），但进一步细化到网络内部结构的每个神经元。&lt;/p&gt;&#xA;&lt;hr&gt;&#xA;&lt;h3 id=&#34;技术细节与实验分析&#34;&gt;&#xA;  技术细节与实验分析&#xA;  &lt;a class=&#34;heading-link&#34; href=&#34;#%e6%8a%80%e6%9c%af%e7%bb%86%e8%8a%82%e4%b8%8e%e5%ae%9e%e9%aa%8c%e5%88%86%e6%9e%90&#34;&gt;&#xA;    &lt;i class=&#34;fa-solid fa-link&#34; aria-hidden=&#34;true&#34; title=&#34;Link to heading&#34;&gt;&lt;/i&gt;&#xA;    &lt;span class=&#34;sr-only&#34;&gt;Link to heading&lt;/span&gt;&#xA;  &lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;p&gt;&lt;strong&gt;1. 问题证据：深度网络在长期学习中“僵化”&lt;/strong&gt;&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
